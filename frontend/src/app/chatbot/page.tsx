'use client';

import { useState, useRef, useEffect, useCallback } from 'react';
import BottomNavigation from '@/components/base/BottomNavigation';
import { sendChatMessage, speechToText, textToSpeech } from '@/services/api';

interface Message {
  id: string;
  text: string;
  isUser: boolean;
  timestamp: Date;
}

// Temporary user ID for development
const TEMP_USER_ID = '00000000-0000-0000-0000-000000000001';

export default function ChatbotPage() {
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  const [messages, setMessages] = useState<Message[]>([
    {
      id: '1',
      text: 'ì•ˆë…•í•˜ì„¸ìš”! ë³µì•½ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”. ğŸ˜Š',
      isUser: false,
      timestamp: new Date(),
    },
  ]);
  const [inputText, setInputText] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [isProcessingVoice, setIsProcessingVoice] = useState(false);
  const [ttsEnabled, setTtsEnabled] = useState(true);

  const quickQuestions = [
    'ì´ ì•½ì€ ì‹ì „ì¸ê°€ìš”?',
    'ì¡¸ìŒì´ ì˜¬ ìˆ˜ ìˆë‚˜ìš”?',
    'ë‹¤ë¥¸ ì•½ê³¼ í•¨ê»˜ ë¨¹ì–´ë„ ë˜ë‚˜ìš”?',
    'ë¶€ì‘ìš©ì´ ìˆë‚˜ìš”?',
  ];

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  // TTS: í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ì½ê¸° (OpenAI TTS ì‚¬ìš©)
  const speakText = useCallback(async (text: string) => {
    if (!ttsEnabled || typeof window === 'undefined') return;

    try {
      // OpenAI TTS API í˜¸ì¶œ
      const result = await textToSpeech(text);

      if (result.success && result.audio && !result.use_browser_tts) {
        // ì„œë²„ì—ì„œ ë°›ì€ ì˜¤ë””ì˜¤ ì¬ìƒ
        const audioData = `data:${result.mime_type || 'audio/mpeg'};base64,${result.audio}`;
        const audio = new Audio(audioData);
        audio.play();
      } else {
        // í´ë°±: ë¸Œë¼ìš°ì € TTS ì‚¬ìš©
        window.speechSynthesis.cancel();
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = 'ko-KR';
        utterance.rate = 0.9;
        utterance.pitch = 1;

        const voices = window.speechSynthesis.getVoices();
        const koreanVoice = voices.find(voice => voice.lang.includes('ko'));
        if (koreanVoice) {
          utterance.voice = koreanVoice;
        }

        window.speechSynthesis.speak(utterance);
      }
    } catch (error) {
      console.error('TTS ì˜¤ë¥˜:', error);
      // ì˜¤ë¥˜ ì‹œ ë¸Œë¼ìš°ì € TTS í´ë°±
      window.speechSynthesis.cancel();
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'ko-KR';
      utterance.rate = 0.9;
      window.speechSynthesis.speak(utterance);
    }
  }, [ttsEnabled]);

  // ìŒì„± ëª©ë¡ ë¡œë“œ (TTSìš©)
  useEffect(() => {
    if (typeof window !== 'undefined') {
      window.speechSynthesis.getVoices();
      window.speechSynthesis.onvoiceschanged = () => {
        window.speechSynthesis.getVoices();
      };
    }
  }, []);

  const handleSendMessage = async (text: string) => {
    if (!text.trim() || isLoading) return;

    const userMessage: Message = {
      id: Date.now().toString(),
      text,
      isUser: true,
      timestamp: new Date(),
    };

    setMessages(prev => [...prev, userMessage]);
    setInputText('');
    setIsLoading(true);

    try {
      const response = await sendChatMessage(text, TEMP_USER_ID);
      const botMessage: Message = {
        id: (Date.now() + 1).toString(),
        text: response.message,
        isUser: false,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, botMessage]);

      // TTSë¡œ ì‘ë‹µ ì½ê¸°
      speakText(response.message);
    } catch (error) {
      console.error('Chat API error:', error);
      const errorMessage: Message = {
        id: (Date.now() + 1).toString(),
        text: 'ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
        isUser: false,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, errorMessage]);
    } finally {
      setIsLoading(false);
    }
  };

  // STT: ìŒì„± ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      // ì§€ì›ë˜ëŠ” MIME íƒ€ì… í™•ì¸
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : MediaRecorder.isTypeSupported('audio/webm')
          ? 'audio/webm'
          : 'audio/mp4';

      const mediaRecorder = new MediaRecorder(stream, { mimeType });

      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        stream.getTracks().forEach(track => track.stop());

        // ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬
        const audioBlob = new Blob(audioChunksRef.current, { type: mimeType.split(';')[0] });
        await processVoiceInput(audioBlob, mimeType.split(';')[0]);
      };

      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start();
      setIsListening(true);

    } catch (error) {
      console.error('ë§ˆì´í¬ ì ‘ê·¼ ì˜¤ë¥˜:', error);
      alert('ë§ˆì´í¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    }
  };

  // STT: ìŒì„± ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    if (mediaRecorderRef.current && isListening) {
      mediaRecorderRef.current.stop();
      setIsListening(false);
    }
  };

  // STT: ìŒì„± ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
  const processVoiceInput = async (audioBlob: Blob, mimeType: string) => {
    setIsProcessingVoice(true);

    try {
      // Blobì„ Base64ë¡œ ë³€í™˜
      const reader = new FileReader();
      const base64Promise = new Promise<string>((resolve, reject) => {
        reader.onloadend = () => {
          const base64 = (reader.result as string).split(',')[1];
          resolve(base64);
        };
        reader.onerror = reject;
      });
      reader.readAsDataURL(audioBlob);

      const base64Audio = await base64Promise;

      console.log(`ìŒì„± ë°ì´í„° ì „ì†¡ - í¬ê¸°: ${audioBlob.size} bytes, MIME: ${mimeType}`);

      // API í˜¸ì¶œ
      const result = await speechToText(base64Audio, mimeType);

      console.log('STT ê²°ê³¼:', result);

      if (result.success && result.text) {
        setInputText(result.text);
        // ìë™ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡
        handleSendMessage(result.text);
      } else {
        alert(result.error || 'ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      }

    } catch (error) {
      console.error('ìŒì„± ì²˜ë¦¬ ì˜¤ë¥˜:', error);
      alert('ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì„œë²„ ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.');
    } finally {
      setIsProcessingVoice(false);
    }
  };

  // ìŒì„± ì…ë ¥ í† ê¸€
  const handleVoiceInput = () => {
    if (isListening) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  return (
    <div className="min-h-screen bg-gray-50 flex flex-col">
      <div className="pt-6 px-4">
        <div className="flex items-center justify-between mb-4">
          <h1 className="text-2xl font-bold text-gray-900">AI ë³µì•½ ë„ìš°ë¯¸</h1>
          {/* TTS í† ê¸€ ë²„íŠ¼ */}
          <button
            onClick={() => {
              setTtsEnabled(!ttsEnabled);
              if (ttsEnabled) {
                window.speechSynthesis.cancel();
              }
            }}
            className={`flex items-center space-x-2 px-3 py-2 rounded-lg transition-colors ${
              ttsEnabled
                ? 'bg-blue-100 text-blue-600'
                : 'bg-gray-100 text-gray-500'
            }`}
          >
            <i className={`${ttsEnabled ? 'ri-volume-up-line' : 'ri-volume-mute-line'} text-lg`}></i>
            <span className="text-sm font-medium">{ttsEnabled ? 'ìŒì„± ON' : 'ìŒì„± OFF'}</span>
          </button>
        </div>
      </div>

      {/* Messages */}
      <div className="flex-1 pb-40 px-4 overflow-y-auto">
        <div className="space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${message.isUser ? 'justify-end' : 'justify-start'}`}
            >
              {!message.isUser && (
                <div className="w-10 h-10 bg-blue-500 rounded-full flex items-center justify-center mr-2 flex-shrink-0">
                  <i className="ri-robot-line text-white text-lg"></i>
                </div>
              )}
              <div
                className={`max-w-[75%] px-4 py-3 rounded-2xl ${
                  message.isUser
                    ? 'bg-blue-500 text-white'
                    : 'bg-white text-gray-900 border border-gray-200'
                }`}
              >
                <p className="text-base leading-relaxed">{message.text}</p>
                <p className={`text-xs mt-1 ${
                  message.isUser ? 'text-blue-100' : 'text-gray-500'
                }`}>
                  {message.timestamp.toLocaleTimeString('ko-KR', {
                    hour: '2-digit',
                    minute: '2-digit'
                  })}
                </p>
              </div>
            </div>
          ))}

          {isLoading && (
            <div className="flex justify-start">
              <div className="w-10 h-10 bg-blue-500 rounded-full flex items-center justify-center mr-2 flex-shrink-0">
                <i className="ri-robot-line text-white text-lg"></i>
              </div>
              <div className="bg-white px-4 py-3 rounded-2xl border border-gray-200">
                <div className="flex space-x-1">
                  <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce"></div>
                  <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style={{ animationDelay: '0.1s' }}></div>
                  <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce" style={{ animationDelay: '0.2s' }}></div>
                </div>
              </div>
            </div>
          )}
        </div>

        {/* Quick Questions */}
        {messages.length === 1 && (
          <div className="mt-8">
            <h3 className="text-lg font-semibold text-gray-900 mb-4">
              ìì£¼ ë¬»ëŠ” ì§ˆë¬¸
            </h3>
            <div className="space-y-2">
              {quickQuestions.map((question, index) => (
                <button
                  key={index}
                  onClick={() => handleSendMessage(question)}
                  className="w-full text-left p-4 bg-white rounded-xl border border-gray-200 hover:bg-blue-50 hover:border-blue-200 transition-colors"
                >
                  <span className="text-base text-gray-700">{question}</span>
                </button>
              ))}
            </div>
          </div>
        )}

        <div ref={messagesEndRef} />
      </div>

      {/* Input Area */}
      <div className="fixed bottom-20 left-0 right-0 bg-white border-t border-gray-200 p-4">
        <div className="flex items-center space-x-3">
          <div className="flex-1 relative">
            <input
              type="text"
              value={inputText}
              onChange={(e) => setInputText(e.target.value)}
              onKeyPress={(e) => e.key === 'Enter' && handleSendMessage(inputText)}
              placeholder="ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”..."
              disabled={isLoading}
              className="w-full px-4 py-3 pr-12 border border-gray-300 rounded-xl focus:outline-none focus:ring-2 focus:ring-blue-500 focus:border-transparent text-base disabled:bg-gray-100"
            />
            <button
              onClick={() => handleSendMessage(inputText)}
              disabled={isLoading || !inputText.trim()}
              className="absolute right-2 top-1/2 transform -translate-y-1/2 w-8 h-8 flex items-center justify-center bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:bg-gray-300"
            >
              <i className="ri-send-plane-line text-sm"></i>
            </button>
          </div>
          <button
            onClick={handleVoiceInput}
            disabled={isProcessingVoice || isLoading}
            className={`w-12 h-12 flex items-center justify-center rounded-xl transition-colors ${
              isListening
                ? 'bg-red-500 text-white animate-pulse'
                : isProcessingVoice
                  ? 'bg-blue-300 text-white cursor-not-allowed'
                  : 'bg-gray-200 text-gray-600 hover:bg-gray-300 disabled:bg-gray-100 disabled:cursor-not-allowed'
            }`}
          >
            <i className={`${
              isProcessingVoice
                ? 'ri-loader-4-line animate-spin'
                : isListening
                  ? 'ri-stop-line'
                  : 'ri-mic-line'
            } text-lg`}></i>
          </button>
        </div>

        {isListening && (
          <p className="text-center text-sm text-red-500 mt-2 animate-pulse">
            ğŸ¤ ë“£ê³  ìˆìŠµë‹ˆë‹¤... ë§ì”€ì´ ëë‚˜ë©´ ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ì£¼ì„¸ìš”
          </p>
        )}

        {isProcessingVoice && (
          <p className="text-center text-sm text-blue-500 mt-2">
            â³ ìŒì„±ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...
          </p>
        )}
      </div>

      <BottomNavigation />
    </div>
  );
}
